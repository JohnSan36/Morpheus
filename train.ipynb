{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())  \n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\")\n",
    "\n",
    "response = llm.invoke(\"Olá Gemini\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import redis\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\")\n",
    "EVOLUTION_URL = os.getenv(\"EVOLUTION_URL\")\n",
    "INSTANCE_ID = os.getenv(\"EVOLUTION_INSTANCE\")\n",
    "EVOLUTION_TOKEN = os.getenv(\"EVOLUTION_APIKEY\")\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "#-------------------------------------------------Functions---------------------------------------------------------------\n",
    "\n",
    "def obter_hora_e_data_atual():\n",
    "    agora = datetime.now()\n",
    "    return agora.strftime(\"%d-%m-%Y - %H:%M:%S\")\n",
    "\n",
    "def get_memory_for_user(whatsapp):\n",
    "    memory = RedisChatMessageHistory(\n",
    "        session_id=whatsapp, \n",
    "        url=REDIS_URL)\n",
    "    return ConversationBufferMemory(return_messages=True, memory_key=\"memory\", chat_memory=memory)\n",
    "\n",
    "def get_memory_for_user_gemini(session_id_key: str):\n",
    "    chat_memory = RedisChatMessageHistory(\n",
    "        session_id=session_id_key, \n",
    "        url=REDIS_URL)\n",
    "    return ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\", chat_memory=chat_memory)\n",
    "\n",
    "\n",
    "#------------------------------------------------Webhooks-------------------------------------------------------------------\n",
    "\n",
    "user_id = \"John Santos\"\n",
    "user_number = \"5541996143338\"\n",
    "data_atual = obter_hora_e_data_atual()\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------------------------------Tools----------------------------------------------------------\n",
    "    \n",
    "class Enviar_Evolution(BaseModel):\n",
    "    texto: str = Field(description=\"Mensagem a ser enviada\")\n",
    "\n",
    "@tool(args_schema=Enviar_Evolution)\n",
    "def enviar_msg(texto: str):\n",
    "    \"\"\"Envia uma mensagem de whatsapp ao usuario\"\"\"\n",
    "    url = f\"{EVOLUTION_URL}/message/sendText/{INSTANCE_ID}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\", \n",
    "        \"apikey\": EVOLUTION_TOKEN\n",
    "    }\n",
    "    payload = {\n",
    "        \"number\": \"5541996143338\", \n",
    "        \"text\": texto, \n",
    "        \"delay\": 800\n",
    "    }\n",
    "    responsta = requests.post(url, headers=headers, json=payload)\n",
    "    responsta.raise_for_status()\n",
    "    return responsta.json()\n",
    "\n",
    "@tool\n",
    "def excluir_memoria():\n",
    "    \"\"\"Exclui a memoria da conversa quando solicitado\"\"\"\n",
    "    r = redis.from_url(REDIS_URL, decode_responses=True)\n",
    "    session_prefix = f\"message_store:{user_id}\"\n",
    "    chaves = r.keys(session_prefix + \"*\")\n",
    "    for chave in chaves:\n",
    "        r.delete(chave)\n",
    "\n",
    "tools = [enviar_msg, excluir_memoria]\n",
    "memoria_gemini = get_memory_for_user_gemini(user_id)\n",
    "memoria = get_memory_for_user(user_id)\n",
    "\n",
    "#--------------------------------------------------Tools----------------------------------------------------------\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"\"\"\n",
    "        Você é Morpheus, um assistente disruptivo. A data atual é {data_atual}.\n",
    "        Não use asteriscos, listas devem começar com '-'.\n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"memory\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "prompt_gemini = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é Morpheus, um assistente disruptivo.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\") \n",
    "])\n",
    "\n",
    "LLM_PROVIDER = \"gemini\" \n",
    "\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=api_key, temperature=0.0)\n",
    "    tools_json = [convert_to_openai_function(t) for t in tools]\n",
    "    pass_through = RunnablePassthrough.assign(agent_scratchpad=lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"]))\n",
    "    chain = pass_through | prompt | llm.bind(functions=tools_json) | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        memory=memoria,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True\n",
    "    )\n",
    "\n",
    "elif LLM_PROVIDER == \"gemini\":\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GOOGLE_API_KEY, temperature=0.0)\n",
    "    chain = create_tool_calling_agent(llm, tools, prompt_gemini)\n",
    "\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        memory=memoria_gemini,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True, \n",
    "        handle_parsing_errors=True  \n",
    "    )\n",
    "\n",
    "\n",
    "resposta = agent_executor.invoke({\"input\": \"qual foi a ultima mensagem que lhe enviei?\"})\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funtional selection of Gpt an Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\")\n",
    "EVOLUTION_URL = os.getenv(\"EVOLUTION_URL\")\n",
    "INSTANCE_ID = os.getenv(\"EVOLUTION_INSTANCE\")\n",
    "EVOLUTION_TOKEN = os.getenv(\"EVOLUTION_APIKEY\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# ------------------------------------------------- Functions ---------------------------------------------------------------\n",
    "\n",
    "def obter_hora_e_data_atual():\n",
    "    agora = datetime.now()\n",
    "    return agora.strftime(\"%d-%m-%Y - %H:%M:%S\")\n",
    "\n",
    "def get_memory(session_id_key: str, memory_key_name: str):\n",
    "    chat_memory = RedisChatMessageHistory(\n",
    "        session_id=session_id_key,\n",
    "        url=REDIS_URL\n",
    "    )\n",
    "    return ConversationBufferMemory(return_messages=True, memory_key=memory_key_name, chat_memory=chat_memory, output_key='output')\n",
    "\n",
    "# ------------------------------------------------ Webhooks -------------------------------------------------------------------\n",
    "\n",
    "user_id = \"John_Santos\"\n",
    "user_number = \"5541996143338\"\n",
    "data_atual = obter_hora_e_data_atual()\n",
    "\n",
    "# -------------------------------------------------- Tools ----------------------------------------------------------\n",
    "\n",
    "class Enviar_Evolution(BaseModel):\n",
    "    texto: str = Field(description=\"Mensagem a ser enviada\")\n",
    "\n",
    "@tool(args_schema=Enviar_Evolution)\n",
    "def enviar_msg(texto: str):\n",
    "    \"\"\"Envia uma mensagem de whatsapp ao usuario\"\"\"\n",
    "    url = f\"{EVOLUTION_URL}/message/sendText/{INSTANCE_ID}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"apikey\": EVOLUTION_TOKEN\n",
    "    }\n",
    "    payload = {\n",
    "        \"number\": user_number,\n",
    "        \"text\": texto,\n",
    "        \"options\": {\"delay\": 800}\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Erro na requisição para Evolution API: {e}\"\n",
    "    \n",
    "\n",
    "@tool\n",
    "def excluir_memoria():\n",
    "    \"\"\"Exclui a memoria da conversa atual (session_id) do Redis.\"\"\"\n",
    "    chat_memory_to_clear = RedisChatMessageHistory(\n",
    "        session_id=user_id,\n",
    "        url=REDIS_URL\n",
    "    )\n",
    "    chat_memory_to_clear.clear()\n",
    "    return f\"Memória para a sessão '{user_id}' foi excluída com sucesso.\"\n",
    "\n",
    "\n",
    "tools = [enviar_msg, excluir_memoria]\n",
    "\n",
    "# -------------------------------------------------- Prompts ----------------------------------------------------------\n",
    "\n",
    "\n",
    "prompt_openai_format = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"Você é Morpheus (OpenAI). Data: {data_atual}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"memory\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "\n",
    "prompt_gemini_format = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "        f\"Você é Morpheus (Gemini), um assistente que mantém o contexto da conversa.\"\n",
    "        \"**Instruções para o uso de ferramentas:**\\n\"\n",
    "        \"- **Para enviar uma mensagem**: Se o usuário solicitar 'enviar uma mensagem' ou 'enviar um ', utilize a ferramenta\\n\"\n",
    "        \"- **Para excluir a memória**: Se o usuário pedir para 'excluir a memória', 'limpar a conversa' ou frases similares, utilize a ferramenta `excluir_memoria`.\\n\\n\"\n",
    "        \"Responda de forma útil e concisa, usando as ferramentas quando apropriado.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "\n",
    "LLM_PROVIDER = \"gemini\" \n",
    "\n",
    "\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "\n",
    "    active_memory = get_memory(user_id, \"memory\")\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=OPENAI_API_KEY, temperature=0.0)\n",
    "    tools_json = [convert_to_openai_function(t) for t in tools]\n",
    "    chain = RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])) | prompt_openai_format | llm.bind(functions=tools_json) | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        memory=active_memory,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "\n",
    "\n",
    "elif LLM_PROVIDER == \"gemini\":\n",
    "\n",
    "    active_memory = get_memory(user_id, \"chat_history\")\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\", google_api_key=GOOGLE_API_KEY, temperature=0.5) \n",
    "    chain = create_tool_calling_agent(llm, tools, prompt_gemini_format) \n",
    "\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        memory=active_memory, \n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "\n",
    "input_1 = \"Qual é seu nome.\"\n",
    "resposta_1 = agent_executor.invoke({\"input\": input_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool # Adicionado o import que faltava na sua última versão\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "import redis\n",
    "import os\n",
    "import requests \n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\")\n",
    "EVOLUTION_URL = os.getenv(\"EVOLUTION_URL\")\n",
    "INSTANCE_ID = os.getenv(\"EVOLUTION_INSTANCE\")\n",
    "EVOLUTION_TOKEN = os.getenv(\"EVOLUTION_APIKEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "user_number = \"5541999999999\" \n",
    "\n",
    "def get_memory_for_user(session_id_key: str):\n",
    "    chat_memory = RedisChatMessageHistory(\n",
    "        session_id=session_id_key, \n",
    "        url=REDIS_URL)\n",
    "    return ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\", chat_memory=chat_memory)\n",
    "\n",
    "user_id = \"John_Santos_Test_Session\"\n",
    "memoria = get_memory_for_user(user_id)\n",
    "\n",
    "class Enviar_Evolution(BaseModel):\n",
    "    texto: str = Field(description=\"Mensagem a ser enviada para o WhatsApp do usuário.\")\n",
    "\n",
    "@tool(args_schema=Enviar_Evolution)\n",
    "def enviar_msg(texto: str):\n",
    "    \"\"\"Envia uma mensagem de whatsapp ao usuario\"\"\"\n",
    "    url = f\"{EVOLUTION_URL}/message/sendText/{INSTANCE_ID}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\", \n",
    "        \"apikey\": EVOLUTION_TOKEN\n",
    "    }\n",
    "    payload = {\n",
    "        \"number\": \"5541996143338\", \n",
    "        \"text\": texto, \n",
    "        \"delay\": 800\n",
    "    }\n",
    "    try:\n",
    "        resposta = requests.post(url, headers=headers, json=payload)\n",
    "        resposta.raise_for_status()\n",
    "        return resposta.json()\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao enviar mensagem: {e}\"\n",
    "\n",
    "@tool\n",
    "def excluir_memoria():\n",
    "    \"\"\"Exclui a memória da conversa atual  do Redis.\"\"\"\n",
    "    try:\n",
    "        r = redis.from_url(REDIS_URL)\n",
    "        num_deleted = r.delete(user_id)\n",
    "        return f\"Memória para a sessão '{user_id}' foi excluída com sucesso.\" if num_deleted > 0 else f\"Nenhuma memória encontrada para a sessão '{user_id}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao tentar excluir memória: {e}\"\n",
    "\n",
    "tools = [enviar_msg, excluir_memoria]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é Morpheus, um assistente disruptivo.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\") \n",
    "])\n",
    "\n",
    "LLM_PROVIDER = \"gemini\" \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GOOGLE_API_KEY, temperature=0.0)\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    memory=memoria,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True, \n",
    "    handle_parsing_errors=True  \n",
    ")\n",
    "\n",
    "primeira_input = \"Envie uma mensagem para mim dizendo que bonito\"\n",
    "resposta1 = agent_executor.invoke({\"input\": primeira_input})\n",
    "print(resposta1.get(\"output\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-Ba2KkqUaXKvp0pPY0pjwlT4lQ6YCS', 'finish_reason': 'stop', 'logprobs': None}, id='run--c3a4c770-2575-4414-a18b-f8fcd80cacd6-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'function_call': {'name': 'enviar_msg', 'arguments': '{\"texto\": \"oi\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--ab03c282-beba-4a7c-8e1a-c98d4d854bd6-0' tool_calls=[{'name': 'enviar_msg', 'args': {'texto': 'oi'}, 'id': 'c5beedc1-961a-46ec-812e-dee81c63c73f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 54, 'output_tokens': 5, 'total_tokens': 59, 'input_token_details': {'cache_read': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Mensagem enviada com sucesso!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--a7a629bd-c99a-4e34-80e2-83d4da9f5c40-0', usage_metadata={'input_tokens': 179, 'output_tokens': 6, 'total_tokens': 185, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_core.tools import tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "\n",
    "class Enviar_Evolution(BaseModel):\n",
    "    texto: str = Field(description=\"Mensagem a ser enviada para o WhatsApp do usuário.\")\n",
    "\n",
    "@tool(args_schema=Enviar_Evolution)\n",
    "def enviar_msg(texto: str):\n",
    "    \"\"\"Envia uma mensagem de whatsapp ao usuario\"\"\"\n",
    "    url = f\"{EVOLUTION_URL}/message/sendText/{INSTANCE_ID}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\", \n",
    "        \"apikey\": EVOLUTION_TOKEN\n",
    "    }\n",
    "    payload = {\n",
    "        \"number\": \"5541996143338\", \n",
    "        \"text\": texto, \n",
    "        \"delay\": 800\n",
    "    }\n",
    "    try:\n",
    "        resposta = requests.post(url, headers=headers, json=payload)\n",
    "        resposta.raise_for_status()\n",
    "        return resposta.json()\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao enviar mensagem: {e}\"\n",
    "\n",
    "@tool\n",
    "def excluir_memoria():\n",
    "    \"\"\"Exclui a memória da conversa atual  do Redis.\"\"\"\n",
    "    try:\n",
    "        r = redis.from_url(REDIS_URL)\n",
    "        num_deleted = r.delete(user_id)\n",
    "        return f\"Memória para a sessão '{user_id}' foi excluída com sucesso.\" if num_deleted > 0 else f\"Nenhuma memória encontrada para a sessão '{user_id}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao tentar excluir memória: {e}\"\n",
    "\n",
    "\n",
    "\n",
    "tools = [enviar_msg, excluir_memoria]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "\n",
    "query = \"eNVIE UMA MENSAGEM  de whatsapp mandando um oi\"\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg)\n",
    "\n",
    "messages.append(ai_msg)\n",
    "\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"enviar_msg\": enviar_msg, \"excluir_memoria\": excluir_memoria}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages\n",
    "\n",
    "llm_with_tools.invoke(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'gen-1747929620-720ZYZvoSrHQK9rg6tWx',\n",
       " 'provider': 'Google',\n",
       " 'model': 'google/gemini-2.5-pro-preview',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1747929620,\n",
       " 'choices': [{'logprobs': None,\n",
       "   'finish_reason': 'stop',\n",
       "   'native_finish_reason': 'STOP',\n",
       "   'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Júlio César (Gaius Julius Caesar, 100 a.C. – 44 a.C.) foi uma das figuras mais importantes e influentes da história de Roma e do mundo ocidental. Ele foi um:\\n\\n1.  **General Romano:** Conhecido por sua genialidade militar, especialmente pela conquista da Gália (atual França e partes da Bélgica, Alemanha e Suíça), que expandiu significativamente o território romano. Suas campanhas são detalhadas em sua obra \"Commentarii de Bello Gallico\" (Comentários sobre a Guerra Gálica).\\n\\n2.  **Estadista e Político:** César teve uma carreira política ambiciosa. Ele formou o Primeiro Triunvirato, uma aliança política informal com Pompeu Magno e Marco Licínio Crasso, que lhe permitiu consolidar poder.\\n\\n3.  **Ditador:** Após vencer uma guerra civil sangrenta contra Pompeu e seus seguidores, César acumulou um poder imenso, sendo nomeado ditador perpétuo. Durante seu governo, implementou diversas reformas políticas e sociais, como a reforma do calendário (o calendário juliano, precursor do nosso calendário gregoriano) e a distribuição de terras.\\n\\n4.  **Figura de Transição:** Ele desempenhou um papel crucial no colapso da República Romana e na subsequente ascensão do Império Romano. Sua morte marcou o início de um novo período de guerras civis que culminaram com a ascensão de seu sobrinho-neto e herdeiro, Otaviano, que se tornou o primeiro imperador romano, Augusto.\\n\\n5.  **Escritor:** Além de suas proezas militares e políticas, César também foi um escritor talentoso, deixando relatos valiosos de suas campanhas militares.\\n\\n**Eventos Chave em sua Vida:**\\n*   **Conquista da Gália:** Entre 58 a.C. e 50 a.C.\\n*   **Guerra Civil contra Pompeu:** Iniciada com a famosa travessia do rio Rubicão em 49 a.C. (\"Alea iacta est\" - \"A sorte está lançada\").\\n*   **Ditadura:** Tornou-se ditador vitalício em 44 a.C.\\n*   **Assassinato:** Foi assassinado por um grupo de senadores liderados por Brutus e Cássio nos Idos de Março (15 de março) de 44 a.C., que temiam que ele se tornasse rei e acabasse de vez com a República.\\n\\n**Legado:**\\n*   Seu nome (\"César\") tornou-se um título imperial usado por seus sucessores e influenciou títulos como \"Kaiser\" (alemão) e \"Czar\" (russo).\\n*   Sua vida e morte inspiraram inúmeras obras de arte, literatura (como a peça \"Júlio César\" de Shakespeare) e filmes.\\n\\nEm resumo, Júlio César foi um líder militar brilhante, um político astuto e uma figura central na transformação de Roma, cujo legado perdura até hoje, moldando a política, a cultura e até mesmo a forma como medimos o tempo.',\n",
       "    'refusal': None,\n",
       "    'reasoning': \"Thinking Through Caesar's Identity\\n\\nOkay, first things first: Who *was* this guy? I need to establish the basics. I'm already mentally sifting through the key periods: late Roman Republic, the rise to power, the crossing of the Rubicon, the political maneuvering... Got it. Next, I'll need to organize this chronologically to ensure clarity.\\n\\n\\nAnalyze the Problem: Who Was He?\\n\\nOkay, I see the objective: a concise profile of Caesar. My first step involves defining the scope – general, statesman, and the timeline. I must incorporate his military successes, his climb to power, the dictatorship, and the assassination. Finally, the enduring legacy.\\n\\n\\nAssess & Refine Structure\\n\\nNow, I've defined the core question and brainstormed the essentials. I must now refine the structure. Thinking chronologically seems logical for the key roles and achievements, before touching on the lasting impact. Also, I will condense the introduction to be a few words, as this is meant to be a brief profile. The Portuguese draft needs a little tweaking for conciseness too.\\n\\n\\n### Reviewing the Blueprint\\n\\nNow, I'm distilling the key steps to outline Caesar's life for this profile. I've pinpointed the core elements: his roles, achievements, ascent, dictatorship, assassination, and enduring influence. I have a clear structure in mind. I'll make a first draft in Portuguese.\\n\\n\\nAssessing the Structure\\n\\nNow, I'm reviewing the structured approach: defining the user's need, key elements, and a logical flow for the profile. I'll ensure clarity and focus, particularly in the Portuguese draft. It's crucial to convey the essence of Caesar efficiently.\\n\\n\\nThinking Critically About Structure\\n\\nOkay, now I'm assessing the overall strategy. I've identified the essential components and mapped out the narrative flow. I'm satisfied with the Portuguese draft's scope and will focus on the language and conciseness for clarity.\\n\\n\\n\"}}],\n",
       " 'usage': {'prompt_tokens': 6,\n",
       "  'completion_tokens': 1809,\n",
       "  'total_tokens': 1815}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "model = \"google/gemini-2.5-pro-preview\"\n",
    "\n",
    "\n",
    "def invoke(message):\n",
    "    response = requests.post(\n",
    "\n",
    "        url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": \"Bearer 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\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        data=json.dumps({\n",
    "            \"model\": model, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": message\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": \"\"\n",
    "                    }\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "invoke(\"quem é julio cesar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
