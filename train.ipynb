{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())  \n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\")\n",
    "\n",
    "response = llm.invoke(\"Olá Gemini\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import redis\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\")\n",
    "EVOLUTION_URL = os.getenv(\"EVOLUTION_URL\")\n",
    "INSTANCE_ID = os.getenv(\"EVOLUTION_INSTANCE\")\n",
    "EVOLUTION_TOKEN = os.getenv(\"EVOLUTION_APIKEY\")\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "#-------------------------------------------------Functions---------------------------------------------------------------\n",
    "\n",
    "def obter_hora_e_data_atual():\n",
    "    agora = datetime.now()\n",
    "    return agora.strftime(\"%d-%m-%Y - %H:%M:%S\")\n",
    "\n",
    "def get_memory_for_user(whatsapp):\n",
    "    memory = RedisChatMessageHistory(\n",
    "        session_id=whatsapp, \n",
    "        url=REDIS_URL)\n",
    "    return ConversationBufferMemory(return_messages=True, memory_key=\"memory\", chat_memory=memory)\n",
    "\n",
    "def get_memory_for_user_gemini(session_id_key: str):\n",
    "    chat_memory = RedisChatMessageHistory(\n",
    "        session_id=session_id_key, \n",
    "        url=REDIS_URL)\n",
    "    return ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\", chat_memory=chat_memory)\n",
    "\n",
    "\n",
    "#------------------------------------------------Webhooks-------------------------------------------------------------------\n",
    "\n",
    "user_id = \"John Santos\"\n",
    "user_number = \"5541996143338\"\n",
    "data_atual = obter_hora_e_data_atual()\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------------------------------Tools----------------------------------------------------------\n",
    "    \n",
    "class Enviar_Evolution(BaseModel):\n",
    "    texto: str = Field(description=\"Mensagem a ser enviada\")\n",
    "\n",
    "@tool(args_schema=Enviar_Evolution)\n",
    "def enviar_msg(texto: str):\n",
    "    \"\"\"Envia uma mensagem de whatsapp ao usuario\"\"\"\n",
    "    url = f\"{EVOLUTION_URL}/message/sendText/{INSTANCE_ID}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\", \n",
    "        \"apikey\": EVOLUTION_TOKEN\n",
    "    }\n",
    "    payload = {\n",
    "        \"number\": \"5541996143338\", \n",
    "        \"text\": texto, \n",
    "        \"delay\": 800\n",
    "    }\n",
    "    responsta = requests.post(url, headers=headers, json=payload)\n",
    "    responsta.raise_for_status()\n",
    "    return responsta.json()\n",
    "\n",
    "@tool\n",
    "def excluir_memoria():\n",
    "    \"\"\"Exclui a memoria da conversa quando solicitado\"\"\"\n",
    "    r = redis.from_url(REDIS_URL, decode_responses=True)\n",
    "    session_prefix = f\"message_store:{user_id}\"\n",
    "    chaves = r.keys(session_prefix + \"*\")\n",
    "    for chave in chaves:\n",
    "        r.delete(chave)\n",
    "\n",
    "tools = [enviar_msg, excluir_memoria]\n",
    "memoria_gemini = get_memory_for_user_gemini(user_id)\n",
    "memoria = get_memory_for_user(user_id)\n",
    "\n",
    "#--------------------------------------------------Tools----------------------------------------------------------\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"\"\"\n",
    "        Você é Morpheus, um assistente disruptivo. A data atual é {data_atual}.\n",
    "        Não use asteriscos, listas devem começar com '-'.\n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"memory\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "prompt_gemini = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é Morpheus, um assistente disruptivo.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\") \n",
    "])\n",
    "\n",
    "LLM_PROVIDER = \"gemini\" \n",
    "\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=api_key, temperature=0.0)\n",
    "    tools_json = [convert_to_openai_function(t) for t in tools]\n",
    "    pass_through = RunnablePassthrough.assign(agent_scratchpad=lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"]))\n",
    "    chain = pass_through | prompt | llm.bind(functions=tools_json) | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        memory=memoria,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True\n",
    "    )\n",
    "\n",
    "elif LLM_PROVIDER == \"gemini\":\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro-preview-05-06\", google_api_key=GOOGLE_API_KEY, temperature=0.0)\n",
    "    chain = create_tool_calling_agent(llm, tools, prompt_gemini)\n",
    "\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        memory=memoria_gemini,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True, \n",
    "        handle_parsing_errors=True  \n",
    "    )\n",
    "\n",
    "\n",
    "resposta = agent_executor.invoke({\"input\": \"qual foi a ultima mensagem que lhe enviei?\"})\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funtional selection of Gpt an Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `enviar_msg` with `{'texto': 'oi'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'key': {'remoteJid': '554196143338@s.whatsapp.net', 'fromMe': True, 'id': '3EB0B2AA82D8DEFF0F5F5780A3C75C13A03B1B22'}, 'pushName': '', 'status': 'PENDING', 'message': {'conversation': 'oi'}, 'contextInfo': None, 'messageType': 'conversation', 'messageTimestamp': 1748007964, 'instanceId': '40d11540-3974-449a-967f-2b7a28d621b3', 'source': 'unknown'}\u001b[0m\u001b[32;1m\u001b[1;3mEnviei uma mensagem para você dizendo \"oi\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\")\n",
    "EVOLUTION_URL = os.getenv(\"EVOLUTION_URL\")\n",
    "INSTANCE_ID = os.getenv(\"EVOLUTION_INSTANCE\")\n",
    "EVOLUTION_TOKEN = os.getenv(\"EVOLUTION_APIKEY\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# ------------------------------------------------- Functions ---------------------------------------------------------------\n",
    "\n",
    "def obter_hora_e_data_atual():\n",
    "    agora = datetime.now()\n",
    "    return agora.strftime(\"%d-%m-%Y - %H:%M:%S\")\n",
    "\n",
    "def get_memory(session_id_key: str, memory_key_name: str):\n",
    "    chat_memory = RedisChatMessageHistory(\n",
    "        session_id=session_id_key,\n",
    "        url=REDIS_URL\n",
    "    )\n",
    "    return ConversationBufferMemory(return_messages=True, memory_key=memory_key_name, chat_memory=chat_memory, output_key='output')\n",
    "\n",
    "# ------------------------------------------------ Webhooks -------------------------------------------------------------------\n",
    "\n",
    "user_id = \"John_Santos\"\n",
    "user_number = \"5541996143338\"\n",
    "data_atual = obter_hora_e_data_atual()\n",
    "\n",
    "# -------------------------------------------------- Tools ----------------------------------------------------------\n",
    "\n",
    "class Enviar_Evolution(BaseModel):\n",
    "    texto: str = Field(description=\"Mensagem a ser enviada\")\n",
    "\n",
    "@tool(args_schema=Enviar_Evolution)\n",
    "def enviar_msg(texto: str):\n",
    "    \"\"\"Envia uma mensagem de whatsapp ao usuario\"\"\"\n",
    "    url = f\"{EVOLUTION_URL}/message/sendText/{INSTANCE_ID}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"apikey\": EVOLUTION_TOKEN\n",
    "    }\n",
    "    payload = {\n",
    "        \"number\": user_number,\n",
    "        \"text\": texto,\n",
    "        \"options\": {\"delay\": 800}\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Erro na requisição para Evolution API: {e}\"\n",
    "    \n",
    "\n",
    "@tool\n",
    "def excluir_memoria():\n",
    "    \"\"\"Exclui a memoria da conversa atual (session_id) do Redis.\"\"\"\n",
    "    chat_memory_to_clear = RedisChatMessageHistory(\n",
    "        session_id=user_id,\n",
    "        url=REDIS_URL\n",
    "    )\n",
    "    chat_memory_to_clear.clear()\n",
    "    return f\"Memória para a sessão '{user_id}' foi excluída com sucesso.\"\n",
    "\n",
    "\n",
    "tools = [enviar_msg, excluir_memoria]\n",
    "\n",
    "# -------------------------------------------------- Prompts ----------------------------------------------------------\n",
    "\n",
    "\n",
    "prompt_openai_format = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"Você é Morpheus (OpenAI). Data: {data_atual}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"memory\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "\n",
    "prompt_gemini_format = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "        f\"Você é Morpheus (Gemini), um assistente que mantém o contexto da conversa.\"\n",
    "        \"**Instruções para o uso de ferramentas:**\\n\"\n",
    "        \"- **Para enviar uma mensagem**: Se o usuário solicitar 'enviar uma mensagem' ou 'enviar um ', utilize a ferramenta\\n\"\n",
    "        \"- **Para excluir a memória**: Se o usuário pedir para 'excluir a memória', 'limpar a conversa' ou frases similares, utilize a ferramenta `excluir_memoria`.\\n\\n\"\n",
    "        \"Responda de forma útil e concisa, usando as ferramentas quando apropriado.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "\n",
    "\n",
    "LLM_PROVIDER = \"gemini\" \n",
    "\n",
    "\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "\n",
    "    active_memory = get_memory(user_id, \"memory\")\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=OPENAI_API_KEY, temperature=0.0)\n",
    "    tools_json = [convert_to_openai_function(t) for t in tools]\n",
    "    chain = RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])) | prompt_openai_format | llm.bind(functions=tools_json) | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        memory=active_memory,\n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "\n",
    "\n",
    "elif LLM_PROVIDER == \"gemini\":\n",
    "\n",
    "    active_memory = get_memory(user_id, \"chat_history\")\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\", google_api_key=GOOGLE_API_KEY, temperature=0.5) \n",
    "    chain = create_tool_calling_agent(llm, tools, prompt_gemini_format) \n",
    "\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=chain,\n",
    "        memory=active_memory, \n",
    "        tools=tools,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "\n",
    "input_1 = \"Envie uma mensagem para mim dizendo oi?.\"\n",
    "resposta_1 = agent_executor.invoke({\"input\": input_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool # Adicionado o import que faltava na sua última versão\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "import redis\n",
    "import os\n",
    "import requests \n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\")\n",
    "EVOLUTION_URL = os.getenv(\"EVOLUTION_URL\")\n",
    "INSTANCE_ID = os.getenv(\"EVOLUTION_INSTANCE\")\n",
    "EVOLUTION_TOKEN = os.getenv(\"EVOLUTION_APIKEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "user_number = \"5541999999999\" \n",
    "\n",
    "def get_memory_for_user(session_id_key: str):\n",
    "    chat_memory = RedisChatMessageHistory(\n",
    "        session_id=session_id_key, \n",
    "        url=REDIS_URL)\n",
    "    return ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\", chat_memory=chat_memory)\n",
    "\n",
    "user_id = \"John_Santos_Test_Session\"\n",
    "memoria = get_memory_for_user(user_id)\n",
    "\n",
    "class Enviar_Evolution(BaseModel):\n",
    "    texto: str = Field(description=\"Mensagem a ser enviada para o WhatsApp do usuário.\")\n",
    "\n",
    "@tool(args_schema=Enviar_Evolution)\n",
    "def enviar_msg(texto: str):\n",
    "    \"\"\"Envia uma mensagem de whatsapp ao usuario\"\"\"\n",
    "    url = f\"{EVOLUTION_URL}/message/sendText/{INSTANCE_ID}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\", \n",
    "        \"apikey\": EVOLUTION_TOKEN\n",
    "    }\n",
    "    payload = {\n",
    "        \"number\": \"5541996143338\", \n",
    "        \"text\": texto, \n",
    "        \"delay\": 800\n",
    "    }\n",
    "    try:\n",
    "        resposta = requests.post(url, headers=headers, json=payload)\n",
    "        resposta.raise_for_status()\n",
    "        return resposta.json()\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao enviar mensagem: {e}\"\n",
    "\n",
    "@tool\n",
    "def excluir_memoria():\n",
    "    \"\"\"Exclui a memória da conversa atual  do Redis.\"\"\"\n",
    "    try:\n",
    "        r = redis.from_url(REDIS_URL)\n",
    "        num_deleted = r.delete(user_id)\n",
    "        return f\"Memória para a sessão '{user_id}' foi excluída com sucesso.\" if num_deleted > 0 else f\"Nenhuma memória encontrada para a sessão '{user_id}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao tentar excluir memória: {e}\"\n",
    "\n",
    "tools = [enviar_msg, excluir_memoria]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é Morpheus, um assistente disruptivo.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\") \n",
    "])\n",
    "\n",
    "LLM_PROVIDER = \"gemini\" \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GOOGLE_API_KEY, temperature=0.0)\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    memory=memoria,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True, \n",
    "    handle_parsing_errors=True  \n",
    ")\n",
    "\n",
    "primeira_input = \"Envie uma mensagem para mim dizendo que bonito\"\n",
    "resposta1 = agent_executor.invoke({\"input\": primeira_input})\n",
    "print(resposta1.get(\"output\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_core.tools import tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "\n",
    "class Enviar_Evolution(BaseModel):\n",
    "    texto: str = Field(description=\"Mensagem a ser enviada para o WhatsApp do usuário.\")\n",
    "\n",
    "@tool(args_schema=Enviar_Evolution)\n",
    "def enviar_msg(texto: str):\n",
    "    \"\"\"Envia uma mensagem de whatsapp ao usuario\"\"\"\n",
    "    url = f\"{EVOLUTION_URL}/message/sendText/{INSTANCE_ID}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\", \n",
    "        \"apikey\": EVOLUTION_TOKEN\n",
    "    }\n",
    "    payload = {\n",
    "        \"number\": \"5541996143338\", \n",
    "        \"text\": texto, \n",
    "        \"delay\": 800\n",
    "    }\n",
    "    try:\n",
    "        resposta = requests.post(url, headers=headers, json=payload)\n",
    "        resposta.raise_for_status()\n",
    "        return resposta.json()\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao enviar mensagem: {e}\"\n",
    "\n",
    "@tool\n",
    "def excluir_memoria():\n",
    "    \"\"\"Exclui a memória da conversa atual  do Redis.\"\"\"\n",
    "    try:\n",
    "        r = redis.from_url(REDIS_URL)\n",
    "        num_deleted = r.delete(user_id)\n",
    "        return f\"Memória para a sessão '{user_id}' foi excluída com sucesso.\" if num_deleted > 0 else f\"Nenhuma memória encontrada para a sessão '{user_id}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao tentar excluir memória: {e}\"\n",
    "\n",
    "\n",
    "\n",
    "tools = [enviar_msg, excluir_memoria]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "\n",
    "query = \"eNVIE UMA MENSAGEM  de whatsapp mandando um oi\"\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg)\n",
    "\n",
    "messages.append(ai_msg)\n",
    "\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"enviar_msg\": enviar_msg, \"excluir_memoria\": excluir_memoria}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages\n",
    "\n",
    "llm_with_tools.invoke(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "model = \"google/gemini-2.5-pro-preview\"\n",
    "\n",
    "\n",
    "def invoke(message):\n",
    "    response = requests.post(\n",
    "\n",
    "        url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": \"Bearer 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\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        data=json.dumps({\n",
    "            \"model\": model, \n",
    "            \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": message\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                    \"url\": \"\"\n",
    "                    }\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "invoke(\"quem é julio cesar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
